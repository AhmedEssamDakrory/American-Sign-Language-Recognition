{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import skimage.io as io\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.color import rgb2gray , rgb2hsv\n",
    "from skimage.morphology import binary_erosion, binary_dilation, binary_closing,skeletonize, thin\n",
    "from skimage.measure import find_contours\n",
    "from skimage.draw import rectangle\n",
    "from skimage.filters import threshold_otsu, threshold_mean, threshold_li, threshold_isodata, threshold_niblack , median\n",
    "from skimage.morphology import binary_erosion, binary_dilation, binary_closing,skeletonize, thin , disk\n",
    "from skimage.segmentation import flood, flood_fill\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Gamma_Correction(img , c , gamma):\n",
    "    img2 = np.copy(img)\n",
    "    img2 = c*np.power(img , gamma)\n",
    "    return img2\n",
    "\n",
    "def erosion(img , n,m):\n",
    "    img2 = np.copy(img)\n",
    "    for i in range(int(n/2) , img.shape[1]-1-int(n/2) ):\n",
    "        for j in range(int(m/2) , img.shape[0]-1-int(m/2) ):\n",
    "            img2[j,i] = np.sum(img[j-int((m)/2) : j+int((m)/2) + n%2 , i-int((n)/2) : i+int((n)/2) + n%2 ])==n*n        \n",
    "    return img2\n",
    "\n",
    "def dilation(img , n,m):\n",
    "    img2 = np.copy(img)\n",
    "    for i in range(int(n/2) , img.shape[1]-1-int(n/2) ):\n",
    "        for j in range(int(m/2) , img.shape[0]-1-int(m/2) ):\n",
    "            img2[j,i] = np.sum(img[j-int((m)/2) : j+int((m)/2) + n%2 , i-int((n)/2) : i+int((n)/2) + n%2 ])>=1        \n",
    "    return img2\n",
    "\n",
    "def Median(img , n , m):\n",
    "    img2 = np.copy(img)\n",
    "    filt = np.ones((n,m))\n",
    "    for i in range(int(n/2) , img.shape[1]-int(np.ceil(n/2))):\n",
    "        for j in range(int(m/2) , img.shape[0]-int(np.ceil(m/2))):\n",
    "            img2[j,i] = np.median(img[j-int(m/2) : j+int(m/2)+1 , i-int(n/2) : i+int(n/2)+1 ])\n",
    "    return img2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_color_space_model(rgba_frame , hsv_frame , ycbcr_frame):\n",
    "    \n",
    "    # Extracting the blue, red, green and alpha channels\n",
    "    \n",
    "    B = rgba_frame[:,:,0]\n",
    "    G = rgba_frame[:,:,1]\n",
    "    R = rgba_frame[:,:,2]\n",
    "    A = rgba_frame[:,:,3]\n",
    "    \n",
    "    #Extracting the Hue, Saturation and vue channels\n",
    "    \n",
    "    H = hsv_frame[:,:,0]\n",
    "    S = hsv_frame[:,:,1]\n",
    "    V = hsv_frame[:,:,2]\n",
    "    \n",
    "    # Extracting the Y, Cr and Cb channels\n",
    "    \n",
    "    Y = ycbcr_frame[:,:,0]\n",
    "    Cr = ycbcr_frame[:,:,1]\n",
    "    Cb = ycbcr_frame[:,:,2]\n",
    "\n",
    "\n",
    "#     Applying  Thresholding using Log-Chromaticity color space \n",
    "#     n_r = np.ma.divide(R, G)\n",
    "#     n_b = np.ma.divide(B, G)\n",
    "#     log_rg = np.ma.log( n_r )\n",
    "#     log_bg = np.ma.log( n_b )\n",
    "#     condition_1 = (log_rg>=0.15) & (log_rg<=1.1)\n",
    "#     condition_2 = (log_bg>=-4) & (log_bg<=0.3)\n",
    "#     mask_1 = condition_1 & condition_2\n",
    "    \n",
    "    # Extracting masks based on a combination of RGBA, HSV and YCrCb models for skin detection\n",
    "    \n",
    "    mask_rgb = (R>95)&(G>40)&(B>20)&(R>G)&(R>B)&(abs(R-G)>15)&(A>15)\n",
    "    mask_Ycbcr = (Cr > 135)&(Cb>85)&(Y>80)&(Cr <= (1.5862*Cb)+20)&(Cr>=(0.3448*Cb)+76.2069)&(Cr >= (-4.5652*Cb)+234.5652)&(\n",
    "                  Cr <= (-1.15*Cb)+301.75)&(Cr <= (-2.2857*Cb)+432.85)\n",
    "    mask_hsv = ((0.0 <= H) & (H <= 50.0))&((0.23 <= S) &(S <= 0.68))\n",
    "    \n",
    "    mask1 = mask_rgb & mask_Ycbcr\n",
    "    mask2 = mask_rgb & mask_hsv\n",
    "    \n",
    "    return mask1 | mask2\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_centers_of_contours(binary_image):\n",
    "    contours = find_contours(binary_image , 0.8)\n",
    "    centers = []\n",
    "    bounding_boxes = list()\n",
    "    for i in range(len(contours)):\n",
    "        Xmin = int(min(contours[i][:,1]))\n",
    "        Xmax = int(max(contours[i][:,1]))\n",
    "        Ymin = int(min(contours[i][:,0]))\n",
    "        Ymax = int(max(contours[i][:,0]))\n",
    "        if( 100<=(Xmax-Xmin)*(Ymax-Ymin)and (Xmax-Xmin)*(Ymax-Ymin) <= 500):\n",
    "            bounding_boxes.append([Xmin , Xmax , Ymin , Ymax])\n",
    "#             moments = cv2.moments(contours[i])\n",
    "#             centers.append((int(moments['m10']/moments['m00']), int(moments['m01']/moments['m00'])))\n",
    "#             cv2.circle(binary_image, centers[-1], 3, (0, 0, 0), -1)\n",
    "    return bounding_boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_contours(bounding_boxes , img):\n",
    "    \n",
    "    for box in bounding_boxes:\n",
    "        [Xmin, Xmax, Ymin, Ymax] = box\n",
    "        rr, cc = rectangle(start = (Ymin,Xmin), end = (Ymax,Xmax), shape=img.shape)\n",
    "        img[rr, cc] = 1\n",
    "    pass\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def moving_area():\n",
    "    \n",
    "    frame_number = 0\n",
    "    ret, rgb_frame = cap.read()\n",
    "    rgb_frame = cv2.resize(rgb_frame, None, fx=1, fy=1, interpolation=cv2.INTER_AREA)\n",
    "    gray_frame = rgb2gray(rgb_frame) \n",
    "    acc_frame = np.zeros((rgb_frame.shape[0] , rgb_frame.shape[1]))\n",
    "    \n",
    "    while (frame_number < 0):\n",
    "        ret, cur_frame = cap.read()\n",
    "        cur_frame = cv2.resize(cur_frame, None, fx=1, fy=1, interpolation=cv2.INTER_AREA)\n",
    "        cur_frame = rgb2gray(cur_frame)\n",
    "        acc_frame += cur_frame\n",
    "        frame_number += 1 \n",
    "        \n",
    "    acc_frame /= frame_number\n",
    "    diff_frame = abs(acc_frame-gray_frame)\n",
    "    moving_region = np.zeros((rgb_frame.shape[0] , rgb_frame.shape[1]))\n",
    "    moving_region[diff_frame > 0.2] = 1\n",
    "    one_positions = np.argwhere(moving_region == 1)\n",
    "    if(len(one_positions) > 0):\n",
    "        Xmin = min(one_positions[:,0])-20\n",
    "        Xmax = max(one_positions[:,0])+20\n",
    "        Ymin = min(one_positions[:,1])-120\n",
    "        Ymax = max(one_positions[:,1])+120\n",
    "        moving_region[Xmin:Xmax , Ymin:Ymax] = 1\n",
    "    \n",
    "    return moving_region\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ahmed/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:16: RuntimeWarning: invalid value encountered in true_divide\n",
      "  app.launch_new_instance()\n",
      "/home/ahmed/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:19: RuntimeWarning: invalid value encountered in greater\n",
      "/home/ahmed/anaconda3/lib/python3.7/site-packages/skimage/util/dtype.py:135: UserWarning: Possible precision loss when converting from float64 to uint8\n",
      "  .format(dtypeobj_in, dtypeobj_out))\n"
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Check if the webcam is opened correctly\n",
    "if not cap.isOpened():\n",
    "    raise IOError(\"Cannot open webcam\")\n",
    "\n",
    "old_moving_region = [] \n",
    "\n",
    "while True:\n",
    "    \n",
    "    face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "    \n",
    "    ret, rgb_frame = cap.read()\n",
    "    rgb_frame = cv2.resize(rgb_frame, None, fx=1, fy=1, interpolation=cv2.INTER_AREA)\n",
    "    \n",
    "    gray = cv2.cvtColor(rgb_frame, cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
    "    \n",
    "    for (x,y,w,h) in faces: \n",
    "        # To draw a rectangle in a face  \n",
    "        cv2.rectangle(rgb_frame,(x,y),(x+w,y+h),(255,255,0),2)   \n",
    "     \n",
    "    \n",
    "    moving_region = moving_area() \n",
    "    if(np.sum(moving_region) < 1000):\n",
    "        moving_region = old_moving_region\n",
    "    old_moving_region = moving_region\n",
    "    \n",
    "    # converting the rgb space to hsv space color\n",
    "    hsv_frame = cv2.cvtColor(rgb_frame, cv2.COLOR_BGR2HSV)\n",
    "    # converting the rgb space to YCbCr space color\n",
    "    ycbcr_frame = cv2.cvtColor(rgb_frame, cv2.COLOR_BGR2YCR_CB)\n",
    "    \n",
    "    # converintg the rgb space to rgba spave \n",
    "    rgba_frame = cv2.cvtColor(rgb_frame, cv2.COLOR_BGR2BGRA)\n",
    "    \n",
    "    \n",
    "    # the final mask to extract the binary image\n",
    "    mask = multi_color_space_model(rgba_frame , hsv_frame , ycbcr_frame)\n",
    "    \n",
    "    binary_frame = np.zeros((rgb_frame.shape[0] , rgb_frame.shape[1]))\n",
    "    binary_frame2 = np.zeros((rgb_frame.shape[0] , rgb_frame.shape[1]))\n",
    "    mask2 = moving_region==1\n",
    "    binary_frame[mask&mask2] = 1\n",
    "    binary_frame2[mask] = 1\n",
    "    cv2.imshow('ssss', binary_frame2)\n",
    "    for (x,y,w,h) in faces: \n",
    "        # To draw a rectangle in a face  \n",
    "        binary_frame2[y-30:y+h+30 , x:x+w] = 0\n",
    "        \n",
    "    #removing noise\n",
    "    binary_frame2 = median(binary_frame2 , disk(2) )\n",
    "    \n",
    "    cv2.imshow('Input', rgb_frame)\n",
    "    cv2.imshow('Output1', binary_frame2)\n",
    "    \n",
    "    \n",
    "    c = cv2.waitKey(1)\n",
    "    if c == 27:\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "if not cap.isOpened():\n",
    "    raise IOError(\"Cannot open webcam\")\n",
    "while True:\n",
    "    ret, rgb_frame = cap.read()\n",
    "    rgb_frame = cv2.resize(rgb_frame, None, fx=1, fy=1, interpolation=cv2.INTER_AREA)\n",
    "    # converting the rgb space to hsv space color\n",
    "    hsv_frame = cv2.cvtColor(rgb_frame, cv2.COLOR_BGR2HSV)\n",
    "    # converting the rgb space to YCbCr space color\n",
    "    ycbcr_frame = cv2.cvtColor(rgb_frame, cv2.COLOR_BGR2YCR_CB)\n",
    "    \n",
    "    # converintg the rgb space to rgba spave \n",
    "    rgba_frame = cv2.cvtColor(rgb_frame, cv2.COLOR_BGR2BGRA)\n",
    "     # the final mask to extract the binary image\n",
    "    mask = multi_color_space_model(rgba_frame , hsv_frame , ycbcr_frame)\n",
    "    binary_frame = np.zeros((rgb_frame.shape[0] , rgb_frame.shape[1]) , dtype=np.uint8)\n",
    "    binary_frame[mask] = 1\n",
    "#   binary_frame = median(binary_frame , disk(2) )\n",
    "    h, w = binary_frame.shape[:2]\n",
    "    maskk = np.zeros((h+2, w+2), np.uint8)\n",
    "    im_floodfill = np.copy(binary_frame)\n",
    "    \n",
    "    # Floodfill from point (0, 0)\n",
    "    cv2.floodFill(im_floodfill, maskk, (0,0), 255);\n",
    "\n",
    "    # Invert floodfilled image\n",
    "    im_floodfill_inv = cv2.bitwise_not(im_floodfill)\n",
    " \n",
    "    # Combine the two images to get the foreground.\n",
    "    im_out = binary_frame | im_floodfill_inv\n",
    "    \n",
    "    cv2.imshow('Input', rgb_frame)\n",
    "    cv2.imshow('Output2', im_out)\n",
    "    cv2.imshow('Output1', binary_frame)\n",
    "    c = cv2.waitKey(1)\n",
    "    if c == 27:\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2;\n",
    "import numpy as np;\n",
    " \n",
    "# Read image\n",
    "im_in = cv2.imread(\"1.jpg\", cv2.IMREAD_GRAYSCALE);\n",
    " \n",
    "# Threshold.\n",
    "# Set values equal to or above 220 to 0.\n",
    "# Set values below 220 to 255.\n",
    " \n",
    "th, im_th = cv2.threshold(im_in, 220, 255, cv2.THRESH_BINARY_INV);\n",
    " \n",
    "# Copy the thresholded image.\n",
    "im_floodfill = im_th.copy()\n",
    " \n",
    "# Mask used to flood filling.\n",
    "# Notice the size needs to be 2 pixels than the image.\n",
    "h, w = im_th.shape[:2]\n",
    "mask = np.zeros((h+2, w+2), np.uint8)\n",
    " \n",
    "# Floodfill from point (0, 0)\n",
    "cv2.floodFill(im_floodfill, mask, (0,0), 255);\n",
    " \n",
    "# Invert floodfilled image\n",
    "im_floodfill_inv = cv2.bitwise_not(im_floodfill)\n",
    " \n",
    "# Combine the two images to get the foreground.\n",
    "im_out = im_th | im_floodfill_inv\n",
    " \n",
    "# Display images.\n",
    "cv2.imshow(\"Thresholded Image\", im_th)\n",
    "cv2.imshow(\"Floodfilled Image\", im_floodfill)\n",
    "cv2.imshow(\"Inverted Floodfilled Image\", im_floodfill_inv)\n",
    "cv2.imshow(\"Foreground\", im_out)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-5-5322dbb4f082>, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-5-5322dbb4f082>\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    a = cv2::zeros((1,1))\u001b[0m\n\u001b[0m           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "a = cv2::zeros((1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
