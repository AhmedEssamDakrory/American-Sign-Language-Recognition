{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import skimage.io as io\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.color import rgb2gray , rgb2hsv\n",
    "from skimage.morphology import binary_erosion, binary_dilation, binary_closing,skeletonize, thin\n",
    "from skimage.measure import find_contours\n",
    "from skimage.draw import rectangle\n",
    "from skimage.filters import threshold_otsu, threshold_mean, threshold_li, threshold_isodata, threshold_niblack\n",
    "from skimage.morphology import binary_erosion, binary_dilation, binary_closing,skeletonize, thin\n",
    "from skimage.segmentation import flood, flood_fill\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Gamma_Correction(img , c , gamma):\n",
    "    img2 = np.copy(img)\n",
    "    img2 = c*np.power(img , gamma)\n",
    "    return img2\n",
    "\n",
    "def erosion(img , n,m):\n",
    "    img2 = np.copy(img)\n",
    "    for i in range(int(n/2) , img.shape[1]-1-int(n/2) ):\n",
    "        for j in range(int(m/2) , img.shape[0]-1-int(m/2) ):\n",
    "            img2[j,i] = np.sum(img[j-int((m)/2) : j+int((m)/2) + n%2 , i-int((n)/2) : i+int((n)/2) + n%2 ])==n*n        \n",
    "    return img2\n",
    "\n",
    "def dilation(img , n,m):\n",
    "    img2 = np.copy(img)\n",
    "    for i in range(int(n/2) , img.shape[1]-1-int(n/2) ):\n",
    "        for j in range(int(m/2) , img.shape[0]-1-int(m/2) ):\n",
    "            img2[j,i] = np.sum(img[j-int((m)/2) : j+int((m)/2) + n%2 , i-int((n)/2) : i+int((n)/2) + n%2 ])>=1        \n",
    "    return img2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_color_space_model(rgba_frame , hsv_frame , ycbcr_frame):\n",
    "    \n",
    "    # Extracting the blue, red, green and alpha channels\n",
    "    \n",
    "    B = rgba_frame[:,:,0]\n",
    "    G = rgba_frame[:,:,1]\n",
    "    R = rgba_frame[:,:,2]\n",
    "    A = rgba_frame[:,:,3]\n",
    "    \n",
    "    #Extracting the Hue, Saturation and vue channels\n",
    "    \n",
    "    H = hsv_frame[:,:,0]\n",
    "    S = hsv_frame[:,:,1]\n",
    "    V = hsv_frame[:,:,2]\n",
    "    \n",
    "    # Extracting the Y, Cr and Cb channels\n",
    "    \n",
    "    Y = ycbcr_frame[:,:,0]\n",
    "    Cr = ycbcr_frame[:,:,1]\n",
    "    Cb = ycbcr_frame[:,:,2]\n",
    "\n",
    "\n",
    "    # Applying  Thresholding using Log-Chromaticity color space \n",
    "#     n_r = np.ma.divide(R, G)\n",
    "#     n_b = np.ma.divide(B, G)\n",
    "#     log_rg = np.ma.log( n_r )\n",
    "#     log_bg = np.ma.log( n_b )\n",
    "#     condition_1 = (log_rg>=0.15) & (log_rg<=1.1)\n",
    "#     condition_2 = (log_bg>=-4) & (log_bg<=0.3)\n",
    "#     mask_1 = condition_1 & condition_2\n",
    "    \n",
    "    # Extracting masks based on a combination of RGBA, HSV and YCrCb models for skin detection\n",
    "    \n",
    "    mask_rgb = (R>95)&(G>40)&(B>20)&(R>G)&(R>B)&(abs(R-G)>15)&(A>15)\n",
    "    mask_Ycbcr = (Cr > 135)&(Cb>85)&(Y>80)&(Cr <= (1.5862*Cb)+20)&(Cr>=(0.3448*Cb)+76.2069)&(Cr >= (-4.5652*Cb)+234.5652)&(\n",
    "                  Cr <= (-1.15*Cb)+301.75)&(Cr <= (-2.2857*Cb)+432.85)\n",
    "    mask_hsv = ((0.0 <= H) & (H <= 50.0))&((0.23 <= S) &(S <= 0.68))\n",
    "    \n",
    "    mask1 = mask_rgb & mask_Ycbcr\n",
    "    mask2 = mask_rgb & mask_hsv\n",
    "    \n",
    "    return mask1 | mask2\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_centers_of_contours(binary_image):\n",
    "    contours = find_contours(binary_image , 0.8)\n",
    "    centers = []\n",
    "    bounding_boxes = list()\n",
    "    for i in range(len(contours)):\n",
    "        Xmin = int(min(contours[i][:,1]))\n",
    "        Xmax = int(max(contours[i][:,1]))\n",
    "        Ymin = int(min(contours[i][:,0]))\n",
    "        Ymax = int(max(contours[i][:,0]))\n",
    "        if( 100<=(Xmax-Xmin)*(Ymax-Ymin)and (Xmax-Xmin)*(Ymax-Ymin) <= 500):\n",
    "            bounding_boxes.append([Xmin , Xmax , Ymin , Ymax])\n",
    "#             moments = cv2.moments(contours[i])\n",
    "#             centers.append((int(moments['m10']/moments['m00']), int(moments['m01']/moments['m00'])))\n",
    "#             cv2.circle(binary_image, centers[-1], 3, (0, 0, 0), -1)\n",
    "    return bounding_boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_contours(bounding_boxes , img):\n",
    "    \n",
    "    for box in bounding_boxes:\n",
    "        [Xmin, Xmax, Ymin, Ymax] = box\n",
    "        rr, cc = rectangle(start = (Ymin,Xmin), end = (Ymax,Xmax), shape=img.shape)\n",
    "        img[rr, cc] = 1\n",
    "    pass\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def moving_area():\n",
    "    \n",
    "    frame_number = 0\n",
    "    ret, rgb_frame = cap.read()\n",
    "    rgb_frame = cv2.resize(rgb_frame, None, fx=1, fy=1, interpolation=cv2.INTER_AREA)\n",
    "    gray_frame = rgb2gray(rgb_frame) \n",
    "    acc_frame = np.zeros((rgb_frame.shape[0] , rgb_frame.shape[1]))\n",
    "    \n",
    "    while (frame_number < 0):\n",
    "        ret, cur_frame = cap.read()\n",
    "        cur_frame = cv2.resize(cur_frame, None, fx=1, fy=1, interpolation=cv2.INTER_AREA)\n",
    "        cur_frame = rgb2gray(cur_frame)\n",
    "        acc_frame += cur_frame\n",
    "        frame_number += 1 \n",
    "        \n",
    "    acc_frame /= frame_number\n",
    "    diff_frame = abs(acc_frame-gray_frame)\n",
    "    moving_region = np.zeros((rgb_frame.shape[0] , rgb_frame.shape[1]))\n",
    "    moving_region[diff_frame > 0.2] = 1\n",
    "    one_positions = np.argwhere(moving_region == 1)\n",
    "    if(len(one_positions) > 0):\n",
    "        Xmin = min(one_positions[:,0])-20\n",
    "        Xmax = max(one_positions[:,0])+20\n",
    "        Ymin = min(one_positions[:,1])-120\n",
    "        Ymax = max(one_positions[:,1])+120\n",
    "        moving_region[Xmin:Xmax , Ymin:Ymax] = 1\n",
    "    \n",
    "    return moving_region\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ahmed/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:16: RuntimeWarning: invalid value encountered in true_divide\n",
      "  app.launch_new_instance()\n",
      "/home/ahmed/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:19: RuntimeWarning: invalid value encountered in greater\n"
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Check if the webcam is opened correctly\n",
    "if not cap.isOpened():\n",
    "    raise IOError(\"Cannot open webcam\")\n",
    "\n",
    "old_moving_region = [] \n",
    "\n",
    "while True:\n",
    "    \n",
    "#     face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "    \n",
    "    ret, rgb_frame = cap.read()\n",
    "    rgb_frame = cv2.resize(rgb_frame, None, fx=1, fy=1, interpolation=cv2.INTER_AREA)\n",
    "    \n",
    "#     gray = cv2.cvtColor(rgb_frame, cv2.COLOR_BGR2GRAY)\n",
    "#     faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
    "    \n",
    "#     for (x,y,w,h) in faces: \n",
    "#         # To draw a rectangle in a face  \n",
    "#         cv2.rectangle(rgb_frame,(x,y),(x+w,y+h),(255,255,0),2)   \n",
    "     \n",
    "            \n",
    "    moving_region = moving_area() \n",
    "    if(np.sum(moving_region) < 1000):\n",
    "        moving_region = old_moving_region\n",
    "    old_moving_region = moving_region\n",
    "    \n",
    "    # converting the rgb space to hsv space color\n",
    "    hsv_frame = cv2.cvtColor(rgb_frame, cv2.COLOR_BGR2HSV)\n",
    "    # converting the rgb space to YCbCr space color\n",
    "    ycbcr_frame = cv2.cvtColor(rgb_frame, cv2.COLOR_BGR2YCR_CB)\n",
    "    \n",
    "    # converintg the rgb space to rgba spave \n",
    "    rgba_frame = cv2.cvtColor(rgb_frame, cv2.COLOR_BGR2BGRA)\n",
    "    \n",
    "    \n",
    "    # the final mask to extract the binary image\n",
    "    mask = multi_color_space_model(rgba_frame , hsv_frame , ycbcr_frame)\n",
    "    \n",
    "    binary_frame = np.zeros((rgb_frame.shape[0] , rgb_frame.shape[1]))\n",
    "    binary_frame2 = np.zeros((rgb_frame.shape[0] , rgb_frame.shape[1]))\n",
    "    mask2 = moving_region==1\n",
    "    binary_frame[mask&mask2] = 1\n",
    "    binary_frame2[mask] = 1\n",
    "    \n",
    "    #removing noise\n",
    "#     eroded_frame = binary_erosion(binary_frame2 , np.ones((5,5)) )\n",
    "#     dilated_frame = binary_dilation(eroded_frame , np.ones((10,10)) )\n",
    "#     dilated_frame = binary_dilation(dilated_frame , np.ones((5,5)) )\n",
    "\n",
    "    final_frame = np.zeros((rgb_frame.shape[0] , rgb_frame.shape[1]))\n",
    "    final_frame[eroded_frame] = 1\n",
    "    cv2.imshow('Input', rgb_frame)\n",
    "    cv2.imshow('Output', binary_frame2)\n",
    "    cv2.imshow('Output1', final_frame)\n",
    "    \n",
    "    \n",
    "    c = cv2.waitKey(1)\n",
    "    if c == 27:\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
