{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import skimage.io as io\n",
    "from skimage.feature import canny\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.color import rgb2gray , rgb2hsv\n",
    "from skimage.morphology import binary_erosion, binary_dilation, binary_closing,skeletonize, thin\n",
    "from skimage.measure import find_contours\n",
    "from skimage.draw import rectangle\n",
    "from skimage.filters import threshold_otsu, threshold_mean, threshold_li, threshold_isodata, threshold_niblack , median\n",
    "from skimage.morphology import binary_erosion, binary_dilation, binary_closing,skeletonize, thin , disk\n",
    "from skimage.segmentation import flood, flood_fill\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Gamma_Correction(img , c , gamma):\n",
    "    img2 = np.copy(img)\n",
    "    img2 = c*np.power(img , gamma)\n",
    "    return img2\n",
    "\n",
    "def erosion(img , n,m):\n",
    "    img2 = np.copy(img)\n",
    "    for i in range(int(n/2) , img.shape[1]-1-int(n/2) ):\n",
    "        for j in range(int(m/2) , img.shape[0]-1-int(m/2) ):\n",
    "            img2[j,i] = np.sum(img[j-int((m)/2) : j+int((m)/2) + n%2 , i-int((n)/2) : i+int((n)/2) + n%2 ])==n*n        \n",
    "    return img2\n",
    "\n",
    "def dilation(img , n,m):\n",
    "    img2 = np.copy(img)\n",
    "    for i in range(int(n/2) , img.shape[1]-1-int(n/2) ):\n",
    "        for j in range(int(m/2) , img.shape[0]-1-int(m/2) ):\n",
    "            img2[j,i] = np.sum(img[j-int((m)/2) : j+int((m)/2) + n%2 , i-int((n)/2) : i+int((n)/2) + n%2 ])>=1        \n",
    "    return img2\n",
    "\n",
    "def Median(img , n , m):\n",
    "    img2 = np.copy(img)\n",
    "    filt = np.ones((n,m))\n",
    "    for i in range(int(n/2) , img.shape[1]-int(np.ceil(n/2))):\n",
    "        for j in range(int(m/2) , img.shape[0]-int(np.ceil(m/2))):\n",
    "            img2[j,i] = np.median(img[j-int(m/2) : j+int(m/2)+1 , i-int(n/2) : i+int(n/2)+1 ])\n",
    "    return img2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_color_space_model(rgba_frame , hsv_frame , ycbcr_frame):\n",
    "    \n",
    "    # Extracting the blue, red, green and alpha channels\n",
    "    \n",
    "    B = rgba_frame[:,:,0]\n",
    "    G = rgba_frame[:,:,1]\n",
    "    R = rgba_frame[:,:,2]\n",
    "    A = rgba_frame[:,:,3]\n",
    "    \n",
    "    #Extracting the Hue, Saturation and vue channels\n",
    "    \n",
    "    H = hsv_frame[:,:,0]\n",
    "    S = hsv_frame[:,:,1]\n",
    "    V = hsv_frame[:,:,2]\n",
    "    \n",
    "    # Extracting the Y, Cr and Cb channels\n",
    "    \n",
    "    Y = ycbcr_frame[:,:,0]\n",
    "    Cr = ycbcr_frame[:,:,1]\n",
    "    Cb = ycbcr_frame[:,:,2]\n",
    "    \n",
    "    #     Applying  Thresholding using Log-Chromaticity color space \n",
    "    n_r = np.ma.divide(R, G)\n",
    "    n_b = np.ma.divide(B, G)\n",
    "    log_rg = np.ma.log( n_r )\n",
    "    log_bg = np.ma.log( n_b )\n",
    "    condition_1 = (log_rg>=0.15) & (log_rg<=1.1)\n",
    "    condition_2 = (log_bg>=-4) & (log_bg<=0.3)\n",
    "    mask_1 = condition_1 & condition_2\n",
    "    \n",
    "    # Extracting masks based on a combination of RGBA, HSV and YCrCb models for skin detection\n",
    "    \n",
    "    mask_rgb = (R>95)&(G>40)&(B>20)&(R>G)&(R>B)&(abs(R-G)>15)&(A>15)\n",
    "    mask_Ycbcr = (Cr > 135)&(Cb>85)&(Y>80)&(Cr <= (1.5862*Cb)+20)&(Cr>=(0.3448*Cb)+76.2069)&(Cr >= (-4.5652*Cb)+234.5652)&(\n",
    "                  Cr <= (-1.15*Cb)+301.75)&(Cr <= (-2.2857*Cb)+432.85)\n",
    "    mask_hsv = ((0.0 <= H) & (H <= 50.0))&((0.23 <= S/255) & (S/255 <= 0.68))\n",
    "\n",
    "    mask1 = mask_rgb & mask_Ycbcr\n",
    "    mask2 = mask_rgb & mask_hsv\n",
    "    \n",
    "    return mask_1\n",
    "#     return mask_hsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def moving_area(image1 , image2 , image3):\n",
    "    diff1 = np.zeros((image1.shape)) \n",
    "    diff1 = cv2.absdiff(image1,image2) >= 30\n",
    "    diff2 = np.zeros((image1.shape))\n",
    "    diff2 = cv2.absdiff(image1,image3) >= 30\n",
    "    mask = diff1*diff2\n",
    "    mask = binary_erosion(mask , disk(5))\n",
    "    one_positions = np.argwhere(mask >= 1)\n",
    "    moving_region = np.zeros((image2.shape[0] , image2.shape[1]))\n",
    "    \n",
    "    if len(one_positions)> 0:\n",
    "        Xmin = min(one_positions[:,0])\n",
    "        Xmax = max(one_positions[:,0])\n",
    "        Ymin = min(one_positions[:,1])\n",
    "        Ymax = max(one_positions[:,1]) \n",
    "        moving_region[Xmin:Xmax , Ymin:Ymax] = 1\n",
    "    mask1 = np.zeros((image2.shape[0] , image2.shape[1]))\n",
    "    mask1[mask] = 1\n",
    "    cv2.imshow('diff' , mask1)\n",
    "    cv2.imshow('moving region',moving_region)\n",
    "    \n",
    "    return moving_region\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Check if the webcam is opened correctly\n",
    "if not cap.isOpened():\n",
    "    raise IOError(\"Cannot open webcam\")\n",
    "\n",
    "ok_region = False\n",
    "old_moving_region = -1 \n",
    "\n",
    "_,frame1 = cap.read()\n",
    "# converting the image into grayscale image\n",
    "frame1 = cv2.resize(frame1, None, fx=1, fy=1, interpolation=cv2.INTER_AREA)\n",
    "image3 = cv2.cvtColor(frame1,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "_,frame2 = cap.read()\n",
    "# converting the image into grayscale image\n",
    "frame2 = cv2.resize(frame2, None, fx=1, fy=1, interpolation=cv2.INTER_AREA)\n",
    "image2 = cv2.cvtColor(frame2,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "fgbg =cv2.createBackgroundSubtractorKNN(history=1000) #,detectShadows=True)\n",
    "\n",
    "while True:\n",
    "    \n",
    "    ret, rgb_frame = cap.read()\n",
    "    rgb_frame = cv2.resize(rgb_frame, None, fx=1, fy=1, interpolation=cv2.INTER_AREA)\n",
    "    rgb_frame = cv2.GaussianBlur(rgb_frame ,(7,7),cv2.BORDER_DEFAULT) \n",
    "    image1 = cv2.cvtColor(rgb_frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    fgmask = fgbg.apply(rgb_frame)\n",
    "    dilated_fgmask = binary_dilation(fgmask ,disk(3))\n",
    "    fgmask = np.zeros(image1.shape)\n",
    "    fgmask[dilated_fgmask] = 1\n",
    "    \n",
    "    cv2.imshow('frame',fgmask)\n",
    "    \n",
    "    if(not ok_region):\n",
    "        ok_region = True\n",
    "        old_moving_region = np.zeros((rgb_frame.shape[0] , rgb_frame.shape[1]))\n",
    "        \n",
    "    #face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')    \n",
    "    #gray = cv2.cvtColor(rgb_frame, cv2.COLOR_BGR2GRAY)\n",
    "    #faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
    "    \n",
    "    #for (x,y,w,h) in faces: \n",
    "        # To draw a rectangle in a face  \n",
    "        #cv2.rectangle(rgb_frame,(x,y),(x+w,y+h),(255,255,0),2)   \n",
    "     \n",
    "    \n",
    "    # converting the rgb space to hsv space color\n",
    "    hsv_frame = cv2.cvtColor(rgb_frame, cv2.COLOR_BGR2HSV)\n",
    "    # converting the rgb space to YCbCr space color\n",
    "    ycbcr_frame = cv2.cvtColor(rgb_frame, cv2.COLOR_BGR2YCR_CB)\n",
    "    \n",
    "    # converintg the rgb space to rgba spave \n",
    "    rgba_frame = cv2.cvtColor(rgb_frame, cv2.COLOR_BGR2BGRA)\n",
    "    \n",
    "    moving_region = moving_area(image1 , image2 , image3)\n",
    "    if(np.sum(moving_region) <= 10000):\n",
    "        moving_region = old_moving_region\n",
    "    old_moving_region = moving_region\n",
    "    \n",
    "    # the final mask to extract the binary image\n",
    "    mask = multi_color_space_model(rgba_frame , hsv_frame , ycbcr_frame)\n",
    "    \n",
    "    binary_frame2 = np.zeros((rgb_frame.shape[0] , rgb_frame.shape[1]))\n",
    "    binary_frame2[mask] = 1\n",
    "  \n",
    "    #for (x,y,w,h) in faces: \n",
    "        # To draw a rectangle in a face  \n",
    "        #binary_frame2[y-30:y+h+30 , x:x+w] = 0\n",
    "        \n",
    "    #removing noise\n",
    "    eroded_frame = binary_erosion(binary_frame2 , np.ones((3,3)))\n",
    "    dilated_frame = binary_dilation(eroded_frame , np.ones((10,5)))\n",
    "    \n",
    "    binary_frame2 = np.zeros((rgb_frame.shape[0] , rgb_frame.shape[1]))\n",
    "    temp = np.copy(binary_frame2).astype(\"uint8\")\n",
    "    \n",
    "    binary_frame2[dilated_frame] = 1\n",
    "    temp[dilated_frame] = 255\n",
    "    \n",
    "    contours, hierarchy = cv2.findContours(temp, cv2.RETR_TREE, cv2.CHAIN_APPROX_NONE)\n",
    "    bounding_boxes = list()\n",
    "    mask_face = np.zeros((rgb_frame.shape[0] , rgb_frame.shape[1]))\n",
    "    for contour in contours:\n",
    "        x,y,w,h = cv2.boundingRect(contour)\n",
    "        #if( ( (float(w)/h <= 0.9 and float(h)/w >= 1.3) or (float(h)/w <= 0.5 and float(w)/h >= 1.3 ) )):\n",
    "        if( ( (float(w)/h <= 0.93) or (float(h)/w <= 0.5 and float(w)/h >= 1.3 ) )):\n",
    "            mask_face[y:y+h , x:x+w] = 1\n",
    "            cv2.drawContours(rgb_frame, contour, -1, (0, 255, 0), 3)\n",
    "    \n",
    "    #cv2.imshow('binary canny detection', final_frame)\n",
    "#     cv2.imshow('canny detection', cannyImg )\n",
    "\n",
    "    frame_with_hand_only = np.zeros((rgb_frame.shape[0] , rgb_frame.shape[1]))\n",
    "    frame_with_hand_only[(binary_frame2>=1) &  (fgmask >= 1) & (mask_face>=1)] = 1\n",
    "    \n",
    "    cv2.imshow('Input', rgb_frame)\n",
    "    cv2.imshow('Output1', binary_frame2)\n",
    "    cv2.imshow('Final Output', frame_with_hand_only)\n",
    "    #cv2.imshow('moving region',moving_region)\n",
    "    image3 = image2\n",
    "    image2 = image1\n",
    "    \n",
    "    c = cv2.waitKey(1)\n",
    "    if c == 27:\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import cv2\n",
    "\n",
    "# cap = cv2.VideoCapture(0)\n",
    "\n",
    "# fgbg = cv2.createBackgroundSubtractorMOG2()\n",
    "\n",
    "# while(1):\n",
    "#     ret, frame = cap.read()\n",
    "#     if ret == True:\n",
    "#         fgmask = fgbg.apply(frame)\n",
    "\n",
    "#         cv2.imshow('frame',fgmask)\n",
    "#         k = cv2.waitKey(30) & 0xff\n",
    "#         if k == 27:\n",
    "#             break\n",
    "#     else:\n",
    "#         break\n",
    "\n",
    "# cap.release()\n",
    "# cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
